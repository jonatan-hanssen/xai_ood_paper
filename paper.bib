@ARTICLE{9046288,

  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},

  journal={IEEE Transactions on Neural Networks and Learning Systems}, 

  title={A Comprehensive Survey on Graph Neural Networks}, 

  year={2021},

  volume={32},

  number={1},

  pages={4-24},

  keywords={Deep learning;Neural networks;Task analysis;Kernel;Feature extraction;Data mining;Learning systems;Deep learning;graph autoencoder (GAE);graph convolutional networks (GCNs);graph neural networks (GNNs);graph representation learning;network embedding},

  doi={10.1109/TNNLS.2020.2978386}}


@inproceedings{scale,
    title={Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement},
    author={Kai Xu and Rongyu Chen and Gianni Franchi and Angela Yao},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=RDSTjtnqCg}
}

@InProceedings{pixmix,
    author    = {Hendrycks, Dan and Zou, Andy and Mazeika, Mantas and Tang, Leonard and Li, Bo and Song, Dawn and Steinhardt, Jacob},
    title     = {PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16783-16792}
}

@misc{adascale,
      title={AdaSCALE: Adaptive Scaling for OOD Detection},
      author={Sudarshan Regmi},
      year={2025},
      eprint={2503.08023},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.08023},
}


@inproceedings{rotpred,
 author = {Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/a2b15837edac15df90721968986f7f8e-Paper.pdf},
 volume = {32},
 year = {2019}
}

@misc{shapley,
      title={A Unified Approach to Interpreting Model Predictions}, 
      author={Scott Lundberg and Su-In Lee},
      year={2017},
      eprint={1705.07874},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.07874}, 
}

@misc{deeplift,
      title={Learning Important Features Through Propagating Activation Differences}, 
      author={Avanti Shrikumar and Peyton Greenside and Anshul Kundaje},
      year={2019},
      eprint={1704.02685},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1704.02685}, 
}

@misc{mahalanobis,
      title={A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks}, 
      author={Kimin Lee and Kibok Lee and Honglak Lee and Jinwoo Shin},
      year={2018},
      eprint={1807.03888},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1807.03888}, 
}

@misc{nearestneighbour,
      title={Out-of-Distribution Detection with Deep Nearest Neighbors}, 
      author={Yiyou Sun and Yifei Ming and Xiaojin Zhu and Yixuan Li},
      year={2022},
      eprint={2204.06507},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2204.06507}, 
}

@inproceedings{openood,
    title={Open{OOD}: Benchmarking Generalized Out-of-Distribution Detection},
    author={Jingkang Yang and Pengyun Wang and Dejian Zou and Zitang Zhou and Kunyuan Ding and WenXuan Peng and Haoqi Wang and Guangyao Chen and Bo Li and Yiyou Sun and Xuefeng Du and Kaiyang Zhou and Wayne Zhang and Dan Hendrycks and Yixuan Li and Ziwei Liu},
    booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2022},
    url={https://openreview.net/forum?id=gT6j4_tskUt}
}

@article{rosenblatt,
  added-at = {2017-07-19T15:29:59.000+0200},
  author = {Rosenblatt, F.},
  biburl = {https://www.bibsonomy.org/bibtex/214ee8da21c66cd4d00d7ab6eca2d96a9/andreashdez},
  citeulike-article-id = {13697582},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037/h0042519},
  doi = {10.1037/h0042519},
  interhash = {dc0cef9dc06033a04f525efdcde7a660},
  intrahash = {14ee8da21c66cd4d00d7ab6eca2d96a9},
  issn = {0033-295X},
  journal = {Psychological Review},
  keywords = {imported},
  number = 6,
  pages = {386--408},
  posted-at = {2016-05-02 20:23:36},
  priority = {2},
  timestamp = {2017-07-19T15:31:02.000+0200},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain.}},
  url = {http://dx.doi.org/10.1037/h0042519},
  volume = 65,
  year = 1958
}

@book{mitchell,
  added-at = {2022-09-08T09:41:39.000+0200},
  author = {Mitchell, Tom M},
  biburl = {https://www.bibsonomy.org/bibtex/2ea9f893d9d19c182bcf2822eb590fe4f/msteininger},
  interhash = {479a66c32badb3a455fbdcf8e6633a5d},
  intrahash = {ea9f893d9d19c182bcf2822eb590fe4f},
  keywords = {book ml},
  number = 9,
  publisher = {McGraw-hill New York},
  timestamp = {2022-09-08T17:32:10.000+0200},
  title = {Machine learning},
  volume = 1,
  year = 1997
}

@ARTICLE{tingsim,
  title    = "Machine learning in medicine: what clinicians should know",
  author   = "Ting Sim, Jordan Zheng and Fong, Qi Wei and Huang, Weimin and
              Tan, Cher Heng",
  abstract = "With the advent of artificial intelligence (AI), machines are
              increasingly being used to complete complicated tasks, yielding
              remarkable results. Machine learning (ML) is the most relevant
              subset of AI in medicine, which will soon become an integral part
              of our everyday practice. Therefore, physicians should acquaint
              themselves with ML and AI, and their role as an enabler rather
              than a competitor. Herein, we introduce basic concepts and terms
              used in AI and ML, and aim to demystify commonly used AI/ML
              algorithms such as learning methods including neural
              networks/deep learning, decision tree and application domain in
              computer vision and natural language processing through specific
              examples. We discuss how machines are already being used to
              augment the physician's decision-making process, and postulate
              the potential impact of ML on medical practice and medical
              research based on its current capabilities and known limitations.
              Moreover, we discuss the feasibility of full machine autonomy in
              medicine.",
  journal  = "Singapore Med J",
  volume   =  64,
  number   =  2,
  pages    = "91--97",
  month    =  may,
  year     =  2021,
  address  = "India",
  keywords = "Algorithms; artificial intelligence; deep learning; machine
              learning; neural networks",
  language = "en"
}

@article{dlmed,
author = {Alvin Rajkomar  and Jeffrey Dean  and Isaac Kohane },
title = {Machine Learning in Medicine},
journal = {New England Journal of Medicine},
volume = {380},
number = {14},
pages = {1347-1358},
year = {2019},
doi = {10.1056/NEJMra1814259},
URL = {https://www.nejm.org/doi/full/10.1056/NEJMra1814259},
eprint = {https://www.nejm.org/doi/pdf/10.1056/NEJMra1814259},
abstract = { In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. These data are collected and curated to provide the latest evidence-based assessment and recommendations. }
}

@article{hyperkvasir,
  title = {{HyperKvasir, a comprehensive multi-class
    image and video dataset for gastrointestinal endoscopy}},
  author = {
    Borgli, Hanna and Thambawita, Vajira and
    Smedsrud, Pia H and Hicks, Steven and Jha, Debesh and
    Eskeland, Sigrun L and Randel, Kristin Ranheim and
    Pogorelov, Konstantin and Lux, Mathias and
    Nguyen, Duc Tien Dang and Johansen, Dag and
    Griwodz, Carsten and Stensland, H{\aa}kon K and
    Garcia-Ceja, Enrique and Schmidt, Peter T and
    Hammer, Hugo L and Riegler, Michael A and
    Halvorsen, P{\aa}l and de Lange, Thomas
  },
  doi = {10.1038/s41597-020-00622-y},
  issn = {2052-4463},
  journal = {Scientific Data},
  number = {1},
  pages = {283},
  url = {https://doi.org/10.1038/s41597-020-00622-y},
  volume = {7},
  year = {2020}
}

@misc{uncertainty,
      title={Uncertainty Estimation and Out-of-Distribution Detection for Counterfactual Explanations: Pitfalls and Solutions}, 
      author={Eoin Delaney and Derek Greene and Mark T. Keane},
      year={2021},
      eprint={2107.09734},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.09734}, 
}

@InProceedings{generalxaiforood,
author="Sipple, John
and Youssef, Abdou",
editor="Ceci, Michelangelo
and Flesca, Sergio
and Masciari, Elio
and Manco, Giuseppe
and Ra{\'{s}}, Zbigniew W.",
title="A General-Purpose Method for Applying Explainable AI for Anomaly Detection",
booktitle="Foundations of Intelligent Systems",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="162--174",
abstract="The need for explainable AI (XAI) is well established but relatively little has been published outside of the supervised learning paradigm. This paper focuses on a principled approach to applying explainability and interpretability to the task of unsupervised anomaly detection. We argue that explainability is principally an algorithmic task and interpretability is principally a cognitive task, and draw on insights from the cognitive sciences to propose a general-purpose method for practical diagnosis using explained anomalies. We define Attribution Error, and demonstrate, using real-world labeled datasets, that our method based on Integrated Gradients (IG) yields significantly lower attribution errors than alternative methods.",
isbn="978-3-031-16564-1"
}

@misc{nguyen2015deepneuralnetworkseasily,
      title={Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images}, 
      author={Anh Nguyen and Jason Yosinski and Jeff Clune},
      year={2015},
      eprint={1412.1897},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1412.1897}, 
}

@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@misc{goodfellow2015explainingharnessingadversarialexamples,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1412.6572}, 
}

@article{tallon2020explainable,
  title={Explainable AI: Using Shapley Value to Explain Complex Anomaly Detection ML-Based Systems},
  author={Tall{\'o}n-Ballesteros, AJ and Chen, C},
  journal={Machine Learning and Artificial Intelligence: Proceedings of MLIS 2020},
  volume={332},
  pages={152},
  year={2020},
  publisher={IOS Press}
}

@book{combood,
author = {Shekhar, Shashi and Papalexakis, Vagelis and Gao, Jing and Jiang, Zhe and Riondato, Matteo},
title = {Proceedings of the 2024 SIAM International Conference on Data Mining (SDM)},
publisher = {Society for Industrial and Applied Mathematics},
year = {2024},
doi = {10.1137/1.9781611978032},
address = {Philadelphia, PA},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611978032},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611978032}
}


@article{tcydenova2021detection,
  title={Detection of adversarial attacks in AI-based intrusion detection systems using explainable AI},
  author={Tcydenova, Erzhena and Kim, Tae Woo and Lee, Changhoon and Park, Jong Hyuk},
  journal={Human-Centric Comput Inform Sci},
  volume={11},
  year={2021}
}

@article{sturmfels2020visualizing,
  author = {Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In},
  title = {Visualizing the Impact of Feature Attribution Baselines},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/attribution-baselines},
  doi = {10.23915/distill.00022}
}

@INPROCEEDINGS{martinez,
  author={Martinez-Seras, Aitor and Ser, Javier Del and Garcia-Bringas, Pablo},
  booktitle={2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Can Post-hoc Explanations Effectively Detect Out-of-Distribution Samples?}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  keywords={Heating systems;Analytical models;Training data;Machine learning;Predictive models;Data models;Stress measurement;Explainable Artificial Intelligence;Out-of-Distribution (OoD) detection;local explanations},
  doi={10.1109/FUZZ-IEEE55066.2022.9882726}}



@article{kaminski2010quality,
  title={Quality indicators for colonoscopy and the risk of interval cancer},
  author={Kaminski, Michal F and Regula, Jaroslaw and Kraszewska, Ewa and Polkowski, Marcin and Wojciechowska, Urszula and Didkowska, Joanna and Zwierko, Maria and Rupinski, Maciej and Nowacki, Marek P and Butruk, Eugeniusz},
  journal={New England journal of medicine},
  volume={362},
  number={19},
  pages={1795--1803},
  year={2010},
  publisher={Mass Medical Soc}
}


@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@ARTICLE{dnsxai,
  author={Zebin, Tahmina and Rezvy, Shahadate and Luo, Yuan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={An Explainable AI-Based Intrusion Detection System for DNS Over HTTPS (DoH) Attacks}, 
  year={2022},
  volume={17},
  number={},
  pages={2339-2349},
  keywords={Tunneling;Servers;Security;Cryptography;Protocols;Computer crime;Feature extraction;Secure computing;machine learning;intrusion detection system;explainable AI},
  doi={10.1109/TIFS.2022.3183390}}


@article{mahbooba,
author = {Mahbooba, Basim and Timilsina, Mohan and Sahal, Radhya and Serrano, Martin},
title = {Explainable Artificial Intelligence (XAI) to Enhance Trust Management in Intrusion Detection Systems Using Decision Tree Model},
journal = {Complexity},
volume = {2021},
number = {1},
pages = {6634811},
doi = {https://doi.org/10.1155/2021/6634811},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/6634811},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/6634811},
abstract = {Despite the growing popularity of machine learning models in the cyber-security applications (e.g., an intrusion detection system (IDS)), most of these models are perceived as a black-box. The eXplainable Artificial Intelligence (XAI) has become increasingly important to interpret the machine learning models to enhance trust management by allowing human experts to understand the underlying data evidence and causal reasoning. According to IDS, the critical role of trust management is to understand the impact of the malicious data to detect any intrusion in the system. The previous studies focused more on the accuracy of the various classification algorithms for trust in IDS. They do not often provide insights into their behavior and reasoning provided by the sophisticated algorithm. Therefore, in this paper, we have addressed XAI concept to enhance trust management by exploring the decision tree model in the area of IDS. We use simple decision tree algorithms that can be easily read and even resemble a human approach to decision-making by splitting the choice into many small subchoices for IDS. We experimented with this approach by extracting rules in a widely used KDD benchmark dataset. We also compared the accuracy of the decision tree approach with the other state-of-the-art algorithms.},
year = {2021}
}


@ARTICLE{idsxai,
  author={Arreche, Osvaldo and Guntur, Tanish R. and Roberts, Jack W. and Abdallah, Mustafa},
  journal={IEEE Access}, 
  title={E-XAI: Evaluating Black-Box Explainable AI Frameworks for Network Intrusion Detection}, 
  year={2024},
  volume={12},
  number={},
  pages={23954-23988},
  keywords={Explainable AI;Closed box;Network intrusion detection;Robustness;Malware;Network security;Detection algorithms;Internet security;Telecommunication traffic;Data science;Data models;Knowledge discovery;Data mining;NSL-KDD;XAI evaluation;intrusion detection systems;SHAP;explainable AI;network security;LIME;black-box AI;NSL-KDD;CICIDS-2017;RoEduNet-SIMARGL2021},
  doi={10.1109/ACCESS.2024.3365140}}



@misc{cam,
      title={Learning Deep Features for Discriminative Localization}, 
      author={Bolei Zhou and Aditya Khosla and Agata Lapedriza and Aude Oliva and Antonio Torralba},
      year={2015},
      eprint={1512.04150},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{lrp,
    doi = {10.1371/journal.pone.0130140},
    author = {Bach, Sebastian AND Binder, Alexander AND Montavon, Grégoire AND Klauschen, Frederick AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
    year = {2015},
    month = {07},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0130140},
    pages = {1-46},
    abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
    number = {7},
}

@ARTICLE{places365,
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Places: A 10 Million Image Database for Scene Recognition}, 
  year={2018},
  volume={40},
  number={6},
  pages={1452-1464},
  keywords={Object recognition;Deep learning;Image recognition;Leearning (artificial intelligence);Image classification;Image analysis;Scene classification;visual recognition;deep learning;deep feature;image dataset},
  doi={10.1109/TPAMI.2017.2723009}}


@inproceedings{stanforddogs,
author = "Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei",
title = "Novel Dataset for Fine-Grained Image Categorization",
booktitle = "First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition",
year = "2011",
month = "June",
address = "Colorado Springs, CO",
}


@inproceedings{cats,
author = {Zhang, Weiwei and Sun, Jian and Tang, Xiaoou},
year = {2008},
month = {10},
pages = {802-816},
title = {Cat Head Detection - How to Effectively Exploit Shape and Texture Features},
volume = {5305},
isbn = {978-3-540-88692-1},
doi = {10.1007/978-3-540-88693-8_59}
}


@article{evalxai,
author = {Nauta, Meike and Trienes, Jan and Pathak, Shreyasi and Nguyen, Elisa and Peters, Michelle and Schmitt, Yasmin and Schl\"{o}tterer, J\"{o}rg and van Keulen, Maurice and Seifert, Christin},
title = {From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {13s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3583558},
doi = {10.1145/3583558},
abstract = {The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the past 7 years at major AI and ML conferences that introduce an XAI method. We find that one in three papers evaluate exclusively with anecdotal evidence, and one in five papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark, and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training to optimize for accuracy and interpretability simultaneously.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {295},
numpages = {42},
keywords = {Explainable artificial intelligence, interpretable machine learning, evaluation, explainability, interpretability, quantitative evaluation methods, explainable AI, XAI}
}

@article{xaioverview,
title = {Explainable artificial intelligence (XAI) in deep learning-based medical image analysis},
journal = {Medical Image Analysis},
volume = {79},
pages = {102470},
year = {2022},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2022.102470},
url = {https://www.sciencedirect.com/science/article/pii/S1361841522001177},
author = {Bas H.M. {van der Velden} and Hugo J. Kuijf and Kenneth G.A. Gilhuijs and Max A. Viergever},
keywords = {Explainable artificial intelligence, Interpretable deep learning, Medical image analysis, Deep learning, Survey},
abstract = {With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.}
}

@article{pianpanit2021parkinson,
  title={Parkinson’s disease recognition using SPECT image and interpretable AI: A tutorial},
  author={Pianpanit, Theerasarn and Lolak, Sermkiat and Sawangjai, Phattarapong and Sudhawiyangkul, Thapanun and Wilaiprasitporn, Theerawit},
  journal={IEEE Sensors Journal},
  volume={21},
  number={20},
  pages={22304--22316},
  year={2021},
  publisher={IEEE}
}


@article{arras2022clevr,
  title={CLEVR-XAI: A benchmark dataset for the ground truth evaluation of neural network explanations},
  author={Arras, Leila and Osman, Ahmed and Samek, Wojciech},
  journal={Information Fusion},
  volume={81},
  pages={14--40},
  year={2022},
  publisher={Elsevier}
}


@article{xaisurvey,
  title={Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks},
  author={Sajid Nazir and Diane M. Dickson and Muhammad Usman Akram},
  journal={Computers in biology and medicine},
  year={2023},
  volume={156},
  pages={
          106668
        },
  url={https://api.semanticscholar.org/CorpusID:257067347}
}

@misc{intriguing,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      eprint={1312.6199},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{performance,
  author    = {Dargan, Shaveta and Kumar, Munish and Ayyagari, Maruthi Rohit and Kumar, Gulshan},
  title     = {A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning},
  journal   = {Archives of Computational Methods in Engineering},
  volume    = {27},
  number    = {4},
  pages     = {1071--1092},
  year      = {2020},
  month     = {09},
  day       = {01},
  doi       = {10.1007/s11831-019-09344-w},
  issn      = {1886-1784},
  abstract  = {Nowadays, deep learning is a current and a stimulating field of machine learning. Deep learning is the most effective, supervised, time and cost efficient machine learning approach. Deep learning is not a restricted learning approach, but it abides various procedures and topographies which can be applied to an immense speculum of complicated problems. The technique learns the illustrative and differential features in a very stratified way. Deep learning methods have made a significant breakthrough with appreciable performance in a wide variety of applications with useful security tools. It is considered to be the best choice for discovering complex architecture in high-dimensional data by employing back propagation algorithm. As deep learning has made significant advancements and tremendous performance in numerous applications, the widely used domains of deep learning are business, science and government which further includes adaptive testing, biological image classification, computer vision, cancer detection, natural language processing, object detection, face recognition, handwriting recognition, speech recognition, stock market analysis, smart city and many more. This paper focuses on the concepts of deep learning, its basic and advanced architectures, techniques, motivational aspects, characteristics and the limitations. The paper also presents the major differences between the deep learning, classical machine learning and conventional learning approaches and the major challenges ahead. The main intention of this paper is to explore and present chronologically, a comprehensive survey of the major applications of deep learning covering variety of areas, study of the techniques and architectures used and further the contribution of that respective application in the real world. Finally, the paper ends with the conclusion and future aspects.},
  url       = {https://doi.org/10.1007/s11831-019-09344-w}
}

@misc{nullspace,
      title={Outlier Detection through Null Space Analysis of Neural Networks}, 
      author={Matthew Cook and Alina Zare and Paul Gader},
      year={2020},
      eprint={2007.01263},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{energy,
      title={Energy-based Out-of-distribution Detection}, 
      author={Weitang Liu and Xiaoyun Wang and John D. Owens and Yixuan Li},
      year={2021},
      eprint={2010.03759},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vos,
      title={VOS: Learning What You Don't Know by Virtual Outlier Synthesis}, 
      author={Xuefeng Du and Zhaoning Wang and Mu Cai and Yixuan Li},
      year={2022},
      eprint={2202.01197},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{oodoverview,
      title={Generalized Out-of-Distribution Detection: A Survey}, 
      author={Jingkang Yang and Kaiyang Zhou and Yixuan Li and Ziwei Liu},
      year={2024},
      eprint={2110.11334},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{doshivelez,
      title={Towards A Rigorous Science of Interpretable Machine Learning}, 
      author={Finale Doshi-Velez and Been Kim},
      year={2017},
      eprint={1702.08608},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{molnar,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book},
  publisher  = {Independently published}
}

@misc{gradnorm,
      title={On the Importance of Gradients for Detecting Distributional Shifts in the Wild}, 
      author={Rui Huang and Andrew Geng and Yixuan Li},
      year={2021},
      eprint={2110.00218},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{react,
      title={ReAct: Out-of-distribution Detection With Rectified Activations}, 
      author={Yiyou Sun and Chuan Guo and Yixuan Li},
      year={2021},
      eprint={2111.12797},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@Article{diagnostic,
AUTHOR = {Thunold, Håvard Horgen and Riegler, Michael A. and Yazidi, Anis and Hammer, Hugo L.},
TITLE = {A Deep Diagnostic Framework Using Explainable Artificial Intelligence and Clustering},
JOURNAL = {Diagnostics},
VOLUME = {13},
YEAR = {2023},
NUMBER = {22},
ARTICLE-NUMBER = {3413},
URL = {https://www.mdpi.com/2075-4418/13/22/3413},
PubMedID = {37998548},
ISSN = {2075-4418},
ABSTRACT = {An important part of diagnostics is to gain insight into properties that characterize a disease. Machine learning has been used for this purpose, for instance, to identify biomarkers in genomics. However, when patient data are presented as images, identifying properties that characterize a disease becomes far more challenging. A common strategy involves extracting features from the images and analyzing their occurrence in healthy versus pathological images. A limitation of this approach is that the ability to gain new insights into the disease from the data is constrained by the information in the extracted features. Typically, these features are manually extracted by humans, which further limits the potential for new insights. To overcome these limitations, in this paper, we propose a novel framework that provides insights into diseases without relying on handcrafted features or human intervention. Our framework is based on deep learning (DL), explainable artificial intelligence (XAI), and clustering. DL is employed to learn deep patterns, enabling efficient differentiation between healthy and pathological images. Explainable artificial intelligence (XAI) visualizes these patterns, and a novel “explanation-weighted” clustering technique is introduced to gain an overview of these patterns across multiple patients. We applied the method to images from the gastrointestinal tract. In addition to real healthy images and real images of polyps, some of the images had synthetic shapes added to represent other types of pathologies than polyps. The results show that our proposed method was capable of organizing the images based on the reasons they were diagnosed as pathological, achieving high cluster quality and a rand index close to or equal to one.},
DOI = {10.3390/diagnostics13223413}
}



@misc{subspace,
      title={Out-Of-Distribution Detection With Subspace Techniques And Probabilistic Modeling Of Features}, 
      author={Ibrahima Ndiour and Nilesh Ahuja and Omesh Tickoo},
      year={2020},
      eprint={2012.04250},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{nusa,
      title={Outlier Detection through Null Space Analysis of Neural Networks}, 
      author={Matthew Cook and Alina Zare and Paul Gader},
      year={2020},
      eprint={2007.01263},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vim,
      title={ViM: Out-Of-Distribution with Virtual-logit Matching}, 
      author={Haoqi Wang and Zhizhong Li and Litong Feng and Wayne Zhang},
      year={2022},
      eprint={2203.10807},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gdpr,
  title = {Article 71: European Data Protection Board},
  author = {{European Union}},
  year = {2016},
  url = {https://www.privacy-regulation.eu/en/r71.htm},
  note = {Accessed: February 13, 2024}
}

@article{lenet5,
author = {Lecun, Yann and Bottou, Leon and Bengio, Y. and Haffner, Patrick},
year = {1998},
month = {12},
pages = {2278 - 2324},
title = {Gradient-Based Learning Applied to Document Recognition},
volume = {86},
journal = {Proceedings of the IEEE},
doi = {10.1109/5.726791}
}

@misc{gbp,
      title={Striving for Simplicity: The All Convolutional Net}, 
      author={Jost Tobias Springenberg and Alexey Dosovitskiy and Thomas Brox and Martin Riedmiller},
      year={2015},
      eprint={1412.6806},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6806}, 
}

@misc{integratedgradients,
      title={Axiomatic Attribution for Deep Networks}, 
      author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
      year={2017},
      eprint={1703.01365},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.01365}, 
}


@article{ooddl,
AUTHOR = {Cui, Peng and Wang, Jinjia},
TITLE = {Out-of-Distribution (OOD) Detection Based on Deep Learning: A Review},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {21},
ARTICLE-NUMBER = {3500},
URL = {https://www.mdpi.com/2079-9292/11/21/3500},
ISSN = {2079-9292},
ABSTRACT = {Out-of-Distribution (OOD) detection separates ID (In-Distribution) data and OOD data from input data through a model. This problem has attracted increasing attention in the area of machine learning. OOD detection has achieved good intrusion detection, fraud detection, system health monitoring, sensor network event detection, and ecosystem interference detection. The method based on deep learning is the most studied in OOD detection. In this paper, related basic information on OOD detection based on deep learning is described, and we categorize methods according to the training data. OOD detection is divided into supervised, semisupervised, and unsupervised. Where supervised data are used, the methods are categorized according to technical means: model-based, distance-based, and density-based. Each classification is introduced with background, examples, and applications. In addition, we present the latest applications of OOD detection based on deep learning and the problems and expectations in this field.},
DOI = {10.3390/electronics11213500}
}

@misc{mls,
      title={Scaling Out-of-Distribution Detection for Real-World Settings}, 
      author={Dan Hendrycks and Steven Basart and Mantas Mazeika and Andy Zou and Joe Kwon and Mohammadreza Mostajabi and Jacob Steinhardt and Dawn Song},
      year={2022},
      eprint={1911.11132},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1911.11132}, 
}

@misc{adversarial,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{odin,
      title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks}, 
      author={Shiyu Liang and Yixuan Li and R. Srikant},
      year={2020},
      eprint={1706.02690},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{vit,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}


@misc{captum,
    title={Captum: A unified and generic model interpretability library for PyTorch},
    author={Narine Kokhlikyan and Vivek Miglani and Miguel Martin and Edward Wang and Bilal Alsallakh and Jonathan Reynolds and Alexander Melnikov and Natalia Kliushkina and Carlos Araya and Siqi Yan and Orion Reblitz-Richardson},
    year={2020},
    eprint={2009.07896},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@ARTICLE{slic,

  author={Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and Süsstrunk, Sabine},

  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 

  title={SLIC Superpixels Compared to State-of-the-Art Superpixel Methods}, 

  year={2012},

  volume={34},

  number={11},

  pages={2274-2282},

  keywords={Clustering algorithms;Image segmentation;Complexity theory;Image color analysis;Image edge detection;Measurement uncertainty;Approximation algorithms;Superpixels;segmentation;clustering;k-means},

  doi={10.1109/TPAMI.2012.120}}


@misc{jacobgilpytorchcam,
  title={PyTorch library for CAM methods},
  author={Jacob Gildenblat and contributors},
  year={2021},
  publisher={GitHub},
  howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}

@misc{hirescam,
      title={Use HiResCAM instead of Grad-CAM for faithful explanations of convolutional neural networks}, 
      author={Rachel Lea Draelos and Lawrence Carin},
      year={2021},
      eprint={2011.08891},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2011.08891}, 
}


@misc{xgradcam,
      title={Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of CNNs}, 
      author={Ruigang Fu and Qingyong Hu and Xiaohu Dong and Yulan Guo and Yinghui Gao and Biao Li},
      year={2020},
      eprint={2008.02312},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2008.02312}, 
}

@article{pouyanfar2018survey,
  title={A survey on deep learning: Algorithms, techniques, and applications},
  author={Pouyanfar, Samira and Sadiq, Saad and Yan, Yilin and Tian, Haiman and Tao, Yudong and Reyes, Maria Presa and Shyu, Mei-Ling and Chen, Shu-Ching and Iyengar, Sundaraja S},
  journal={ACM computing surveys (CSUR)},
  volume={51},
  number={5},
  pages={1--36},
  year={2018},
  publisher={ACM New York, NY, USA}
}


@article{cifar,
  added-at = {2021-01-21T03:01:11.000+0100},
  author = {Krizhevsky, Alex},
  biburl = {https://www.bibsonomy.org/bibtex/2fe5248afe57647d9c85c50a98a12145c/s364315},
  interhash = {cc2d42f2b7ef6a4e76e47d1a50c8cd86},
  intrahash = {fe5248afe57647d9c85c50a98a12145c},
  keywords = {},
  pages = {32--33},
  timestamp = {2021-01-21T03:01:11.000+0100},
  title = {Learning Multiple Layers of Features from Tiny Images},
  url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf},
  year = 2009
}

@article{nguyen2019machine,
  title={Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey},
  author={Nguyen, Giang and Dlugolinsky, Stefan and Bob{\'a}k, Martin and Tran, Viet and L{\'o}pez Garc{\'\i}a, {\'A}lvaro and Heredia, Ignacio and Mal{\'\i}k, Peter and Hluch{\`y}, Ladislav},
  journal={Artificial Intelligence Review},
  volume={52},
  pages={77--124},
  year={2019},
  publisher={Springer}
}

@misc{legrad,
      title={LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity}, 
      author={Walid Bousselham and Angie Boggust and Sofian Chaybouti and Hendrik Strobelt and Hilde Kuehne},
      year={2025},
      eprint={2404.03214},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.03214}, 
}

@misc{resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@article{bootstrap,
author = {B. Efron},
title = {{Bootstrap Methods: Another Look at the Jackknife}},
volume = {7},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {1 -- 26},
keywords = {bootstrap, discriminant analysis, error rate estimation, jackknife, Nonlinear regression, nonparametric variance estimation, Resampling, subsample values},
year = {1979},
doi = {10.1214/aos/1176344552},
URL = {https://doi.org/10.1214/aos/1176344552}
}


@article{uat,
  title={Approximation by superpositions of a sigmoidal function},
  author={George V. Cybenko},
  journal={Mathematics of Control, Signals and Systems},
  year={1989},
  volume={2},
  pages={303-314},
  url={https://api.semanticscholar.org/CorpusID:3958369}
}

@misc{oodbaseline,
      title={A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2018},
      eprint={1610.02136},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

# v1.5 report
@article{openood15,
  title={OpenOOD v1.5: Enhanced Benchmark for Out-of-Distribution Detection},
  author={Zhang, Jingyang and Yang, Jingkang and Wang, Pengyun and Wang, Haoqi and Lin, Yueqian and Zhang, Haoran and Sun, Yiyou and Du, Xuefeng and Li, Yixuan and Liu, Ziwei and Chen, Yiran and Li, Hai},
  journal={arXiv preprint arXiv:2306.09301},
  year={2023}
}

# full-spectrum OOD detection
@article{yang2022fsood,
    title = {Full-Spectrum Out-of-Distribution Detection},
    author = {Yang, Jingkang and Zhou, Kaiyang and Liu, Ziwei},
    journal={arXiv preprint arXiv:2204.05306},
    year = {2022}
}

# generalized OOD detection framework & survey
@article{yang2021oodsurvey,
    title={Generalized Out-of-Distribution Detection: A Survey},
    author={Yang, Jingkang and Zhou, Kaiyang and Li, Yixuan and Liu, Ziwei},
    journal={arXiv preprint arXiv:2110.11334},
    year={2021}
}

# OOD benchmarks
# NINCO
@inproceedings{bitterwolf2023ninco,
    title={In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation},
    author={Julian Bitterwolf and Maximilian Mueller and Matthias Hein},
    booktitle={ICML},
    year={2023},
    url={https://proceedings.mlr.press/v202/bitterwolf23a.html}
}

@article{pdp,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@article{noxaiblackbox,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{
nac,
title={Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization},
author={Yibing Liu and Chris XING TIAN and Haoliang Li and Lei Ma and Shiqi Wang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=SNGXbZtK6Q}
}

@misc{
reweight,
title={Reweight{OOD}: Loss Reweighting for Distance-based {OOD} Detection},
author={Sudarshan Regmi and Bibek Panthi and Yifei Ming and Prashnna Kumar Gyawali and Danail Stoyanov and Binod Bhattarai},
year={2024},
url={https://openreview.net/forum?id=OJoMzslBIa}
}

@misc{weiper,
      title={WeiPer: OOD Detection using Weight Perturbations of Class Projections}, 
      author={Maximilian Granz and Manuel Heurich and Tim Landgraf},
      year={2024},
      eprint={2405.17164},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.17164}, 
}

@inproceedings{
oe,
title={Deep Anomaly Detection with Outlier Exposure},
author={Dan Hendrycks and Mantas Mazeika and Thomas Dietterich},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxCxhRcY7},
}

@article{ale,
  title={Visualizing the effects of predictor variables in black box supervised learning models},
  author={Apley, Daniel W and Zhu, Jingyu},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={82},
  number={4},
  pages={1059--1086},
  year={2020},
  publisher={Oxford University Press}
}



@misc{rmds,
      title={A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection}, 
      author={Jie Ren and Stanislav Fort and Jeremiah Liu and Abhijit Guha Roy and Shreyas Padhy and Balaji Lakshminarayanan},
      year={2021},
      eprint={2106.09022},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.09022}, 
}

@inproceedings{ ash,
title={Extremely Simple Activation Shaping for Out-of-Distribution Detection},
author={Andrija Djurisic and Nebojsa Bozanic and Arjun Ashok and Rosanne Liu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=ndYXTEL6cZz}
}

@article{acm,
  title={Computing as a discipline},
  author={Denning, Peter J. and Comer, Douglas E and Gries, David and Mulder, Michael C. and Tucker, Allen and Turner, A. Joe and Young, Paul R},
  journal={Computer},
  volume={22},
  number={2},
  pages={63--70},
  year={1989},
  publisher={IEEE}
}


@misc{roar,
      title={A Benchmark for Interpretability Methods in Deep Neural Networks}, 
      author={Sara Hooker and Dumitru Erhan and Pieter-Jan Kindermans and Been Kim},
      year={2019},
      eprint={1806.10758},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1806.10758}, 
}

# SSB
@inproceedings{vaze2021open,
    title={Open-Set Recognition: A Good Closed-Set Classifier is All You Need},
    author={Vaze, Sagar and Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
    booktitle={ICLR},
    year={2022}
}

@article{ying2019gnnexplainer,
  title={Gnnexplainer: Generating explanations for graph neural networks},
  author={Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{
wang2021causal,
title={Causal Screening to Interpret Graph Neural Networks},
author={Xiang Wang and Yingxin Wu and An Zhang and Xiangnan He and Tat-seng Chua},
year={2021},
url={https://openreview.net/forum?id=nzKv5vxZfge}
}

@article{DBLP:journals/corr/abs-2003-00982,
  author    = {Vijay Prakash Dwivedi and
               Chaitanya K. Joshi and
               Thomas Laurent and
               Yoshua Bengio and
               Xavier Bresson},
  title     = {Benchmarking Graph Neural Networks},
  journal   = {CoRR},
  volume    = {abs/2003.00982},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.00982},
  eprinttype = {arXiv},
  eprint    = {2003.00982},
  timestamp = {Sat, 23 Jan 2021 01:14:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-00982.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{achanta2012slic,
  title={SLIC superpixels compared to state-of-the-art superpixel methods},
  author={Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and S{\"u}sstrunk, Sabine},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={34},
  number={11},
  pages={2274--2282},
  year={2012},
  publisher={IEEE}
}

@InProceedings{10.1007/978-3-030-65351-4_12,
author="Nikolentzos, Giannis
and Thomas, Michalis
and Rivera, Ad{\'i}n Ram{\'i}rez
and Vazirgiannis, Michalis",
editor="Benito, Rosa M.
and Cherifi, Chantal
and Cherifi, Hocine
and Moro, Esteban
and Rocha, Luis Mateus
and Sales-Pardo, Marta",
title="Image Classification Using Graph-Based Representations and Graph Neural Networks",
booktitle="Complex Networks {\&} Their Applications IX",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="142--153",
abstract="Image classification is an important, real-world problem that arises in many contexts. To date, convolutional neural networks (CNNs) are the state-of-the-art deep learning method for image classification since these models are naturally suited to problems where the coordinates of the underlying data representation have a grid structure. On the other hand, in recent years, there is a growing interest in mapping data from different domains to graph structures. Such approaches proved to be quite successful in different domains including physics, chemoinformatics and natural language processing. In this paper, we propose to represent images as graphs and capitalize on well-established neural network architectures developed for graph-structured data to deal with image-related tasks. The proposed models are evaluated experimentally in image classification tasks, and are compared with standard CNN architectures. Results show that the proposed models are very competitive, and yield in most cases accuracies better or comparable to those of the CNNs.",
isbn="978-3-030-65351-4"
}

@article{gradcam,
   title={Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
   volume={128},
   ISSN={1573-1405},
   url={http://dx.doi.org/10.1007/s11263-019-01228-7},
   DOI={10.1007/s11263-019-01228-7},
   number={2},
   journal={International Journal of Computer Vision},
   publisher={Springer Science and Business Media LLC},
   author={Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
   year={2019},
   month=oct, pages={336–359}
}

@misc{lime,
      title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1602.04938},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1602.04938}, 
}

@misc{cam,
      title={Learning Deep Features for Discriminative Localization}, 
      author={Bolei Zhou and Aditya Khosla and Agata Lapedriza and Aude Oliva and Antonio Torralba},
      year={2015},
      eprint={1512.04150},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imagewoof,
    author    = "Jeremy Howard",
    title     = "Imagewoof",
    url       = "https://github.com/fastai/imagenette/",
    year = {2022}
}

@inproceedings{gradcamplusplus,
   title={Grad-CAM++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks},
   url={http://dx.doi.org/10.1109/WACV.2018.00097},
   DOI={10.1109/wacv.2018.00097},
   booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
   publisher={IEEE},
   author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
   year={2018},
   month=mar }


@INPROCEEDINGS{highfreq,

  author={Abello, Antonio A. and Hirata, Roberto and Wang, Zhangyang},

  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 

  title={Dissecting the High-Frequency Bias in Convolutional Neural Networks}, 

  year={2021},

  volume={},

  number={},

  pages={863-871},

  keywords={Computer vision;Conferences;Computer architecture;Frequency conversion;Robustness;Frequency diversity;Pattern recognition},

  doi={10.1109/CVPRW53098.2021.00096}}


@INPROCEEDINGS{superpixel,

  author={Ren and Malik},

  booktitle={Proceedings Ninth IEEE International Conference on Computer Vision}, 

  title={Learning a classification model for segmentation}, 

  year={2003},

  volume={},

  number={},

  pages={10-17 vol.1},

  keywords={Image segmentation;Humans;Brightness;Image databases;Computer science;Information analysis;Partitioning algorithms;Design optimization;Computer vision;Logistics},

  doi={10.1109/ICCV.2003.1238308}}


@InProceedings{occlusion,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}
